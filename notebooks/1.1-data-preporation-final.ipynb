{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import zipfile\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from dateutil import parser\n",
    "import numpy as np\n",
    "from feature_engine.creation import CyclicalFeatures\n",
    "import re\n",
    "import spacy \n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = os.path.join('../data/raw')\n",
    "with zipfile.ZipFile(os.path.join(data_path,'ml-100k.zip'), 'r') as zip_ref:\n",
    "    zip_ref.extractall(data_path)\n",
    "data_path = os.path.join('../data/raw/ml-100k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(os.path.join(data_path, \"u.data\"), sep=\"\\t\", header=None)\n",
    "data.columns = [\"user_id\", \"item_id\", \"rating\", \"timestamp\"]\n",
    "item = pd.read_csv(os.path.join(data_path, \"u.item\"), sep=\"|\", encoding='latin-1', header=None, index_col=0)\n",
    "user = pd.read_csv(os.path.join(data_path, \"u.user\"), sep= \"|\", encoding='latin-1', header=None, index_col=0, names=[\"id\", \"age\", \"gender\", \"occupation\", \"zip_code\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def date_encoder(date_series):\n",
    "    date_series = date_series.apply(lambda x: (parser.parse(x).day, parser.parse(x).month, parser.parse(x).year)).apply(pd.Series)\n",
    "    date_series.columns = [\"day\", \"month\", \"year\"]\n",
    "    cyclical = CyclicalFeatures(variables=[\"day\", \"month\"], drop_original=True)\n",
    "    date_series = cyclical.fit_transform(date_series)\n",
    "    date_series[\"year\"] = (date_series[\"year\"]-1900)/(2000-1900)\n",
    "    return date_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_title(title_series):\n",
    "    year_series = title_series.apply(lambda x: int(re.findall('\\((\\d{4})\\)(?:(?!\\(\\d{4}\\)).)*$', x.rstrip())[0]))\n",
    "    year_series = (year_series-1900)/(2000-1900)\n",
    "    title_series = title_series.apply(lambda x: re.sub('\\((\\d{4})\\)(?:(?!\\(\\d{4}\\)).)*$', '', x.rstrip()).rstrip())\n",
    "    devided_series = pd.concat([title_series, year_series], axis=1)\n",
    "    devided_series.columns = [\"title\", \"release_year\"]\n",
    "    return devided_series"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def embed_title(title_series):\n",
    "    nlp = spacy.load(\"en_core_web_sm\")\n",
    "    tokenizer = nlp.tokenizer\n",
    "    embedded_title = []\n",
    "    for text in title_series:\n",
    "        doc = nlp(tokenizer(text)) # Extract word embeddings\n",
    "        embedded_title.append(doc.vector)\n",
    "\n",
    "    # Convert the embedded data to a DataFrame\n",
    "    titles_embedded = pd.DataFrame(embedded_title)\n",
    "    return titles_embedded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df, df2, df3):\n",
    "\n",
    "    # Encode timestamd in u.data\n",
    "    df[\"timestamp\"] = df[\"timestamp\"].apply(lambda x: datetime.utcfromtimestamp(x).strftime('%d-%b-%Y'))\n",
    "    date_df = date_encoder(df[\"timestamp\"])\n",
    "    df = pd.concat([df, date_df], axis=1)\n",
    "    df = df.drop(columns=[\"timestamp\"])\n",
    "\n",
    "    # Remove NaN values in u.item\n",
    "    df2 = df2.drop(columns=[3,4])\n",
    "    df2 = df2.dropna()\n",
    "\n",
    "    # Encode video release date in u.item\n",
    "    date_df2 = date_encoder(df2[2])\n",
    "    df2 = pd.concat([df2, date_df2], axis=1)\n",
    "    df2 = df2.drop(columns=[2])\n",
    "\n",
    "    # Get release year from title in u.item\n",
    "    df2 = pd.concat([df2, preprocess_title(df2[1])], axis=1)\n",
    "    df2 = df2.drop(columns=[1])\n",
    "\n",
    "    # Embed titles\n",
    "    df2 = pd.concat([df2, embed_title(df2[\"title\"])], axis=1)\n",
    "    df2 = df2.drop(columns=[\"title\"])\n",
    "    df2 = df2.dropna()\n",
    "\n",
    "    # Encode occupation\n",
    "    df3 = pd.concat([df3, pd.get_dummies(df3[\"occupation\"]).astype(int)], axis=1) \n",
    "    df3 = df3.drop(columns=[\"occupation\"])\n",
    "\n",
    "    # Encode gender\n",
    "    encoder = OrdinalEncoder()\n",
    "    encoded_gender = encoder.fit_transform(df3[\"gender\"].values.reshape(-1, 1))\n",
    "    encoded_gender = pd.Series(encoded_gender.flatten())\n",
    "    encoded_gender.index+=1\n",
    "    df3[\"gender\"] = encoded_gender\n",
    "\n",
    "    # Normalize age\n",
    "    df3[\"age\"] = (df3[\"age\"]-df3[\"age\"].min())/(df3[\"age\"].max()-df3[\"age\"].min())\n",
    "\n",
    "    # Remove unused data\n",
    "    df3.drop(columns=[\"zip_code\"])\n",
    "\n",
    "    # Filter u.data for unexisting indicies\n",
    "    df = df.drop_duplicates(subset=[\"user_id\", \"item_id\"])\n",
    "    df = df[df[\"item_id\"].isin(df2.index)]\n",
    "    df = df[df[\"user_id\"].isin(df3.index)]\n",
    "\n",
    "    # Merge DataFrames at one\n",
    "    df2 = pd.merge(df2, df, left_index=True, right_on='item_id', how='right')\n",
    "    df2 = pd.merge(df2, df3, left_on=[\"user_id\"], right_index=True, how='right')\n",
    "\n",
    "    return df2.drop(columns=[\"rating\"]), df2[\"rating\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = train_test_split(df, test_size=0.2, random_state=13)\n",
    "train_x, train_y = preprocess_data(train)\n",
    "test_x, test_y = preprocess_data(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
